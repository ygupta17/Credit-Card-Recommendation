{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting numpy<2,>=1.22.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.11.8-cp310-cp310-macosx_11_0_arm64.whl (454 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.7.4\n",
      "  Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-community<0.4.0,>=0.3.0\n",
      "  Downloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai<2.0.0,>=1.54.0\n",
      "  Downloading openai-1.55.2-py3-none-any.whl (389 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken<1,>=0.7\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.4/982.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.0-cp310-cp310-macosx_11_0_arm64.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting attrs>=17.3.0\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.12-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.7/248.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>4\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.8.0-cp310-cp310-macosx_11_0_arm64.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting pydantic-core==2.27.1\n",
      "  Downloading pydantic_core-2.27.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.2.2)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, tqdm, tenacity, SQLAlchemy, sniffio, regex, PyYAML, pydantic-core, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, jiter, idna, httpx-sse, h11, frozenlist, distro, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, tiktoken, requests-toolbelt, pydantic-settings, httpx, dataclasses-json, aiohttp, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community, langchain_experimental\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.11.8 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 async-timeout-4.0.3 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 dataclasses-json-0.6.7 distro-1.9.0 frozenlist-1.5.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 httpx-sse-0.4.0 idna-3.10 jiter-0.8.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.9 langchain-community-0.3.8 langchain-core-0.3.21 langchain-openai-0.2.10 langchain-text-splitters-0.3.2 langchain_experimental-0.3.3 langsmith-0.1.147 marshmallow-3.23.1 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.55.2 orjson-3.10.12 propcache-0.2.0 pydantic-2.10.2 pydantic-core-2.27.1 pydantic-settings-2.6.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.1 typing-inspect-0.9.0 urllib3-2.2.3 yarl-1.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%pip install python-dotenv\n",
    "%pip install -U langchain langchain_experimental langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_experimental.tabular_synthetic_data.openai import (\n",
    "    OPENAI_TEMPLATE,\n",
    "    create_openai_data_generator,\n",
    ")\n",
    "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
    "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a schema for transactions\n",
    "#transaction categories include housing, healthcare, transportation, utilities, travel, dining, groceries\n",
    "class SpendingSchema(BaseModel):\n",
    "    user_id: str       \n",
    "    month: str        \n",
    "    housing: int   \n",
    "    bills_utilities: int\n",
    "    dining: int\n",
    "    transport: int\n",
    "    fitness: int\n",
    "    travel: int\n",
    "    entertainment: int\n",
    "    savings: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"example\": \"\"\"User ID: U001, Month: January 2023, Housing: 800, Bills & Utilities: 210, Groceries: 400, Dining: 400, Transport: 100, Fitness: 60, Travel: 400, Entertainment: 300, Savings: 1500\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"User ID: U002, Month: January 2023, Housing: 1300, Bills & Utilities: 150, Groceries: 600, Dining: 200, Transport: 250, Fitness: 20, Travel: 100, Entertainment: 700, Savings: 600\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
    "prompt_template = FewShotPromptTemplate(\n",
    "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    examples=examples,\n",
    "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    "    input_variables=[\"subject\", \"extra\"],\n",
    "    example_prompt=OPENAI_TEMPLATE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "`SyntheticDataGenerator` is not fully defined; you should define `BaseCache`, then call `SyntheticDataGenerator.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m synthetic_data_generator \u001b[39m=\u001b[39m create_openai_data_generator(\n\u001b[1;32m      2\u001b[0m     output_schema\u001b[39m=\u001b[39;49mSpendingSchema,\n\u001b[1;32m      3\u001b[0m     llm\u001b[39m=\u001b[39;49mChatOpenAI(\n\u001b[1;32m      4\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m         api_key\u001b[39m=\u001b[39;49mapi_key\n\u001b[1;32m      6\u001b[0m     ), \n\u001b[1;32m      7\u001b[0m     prompt\u001b[39m=\u001b[39;49mprompt_template,\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Yash/OMSCS/Credit-Card-Recommendation/venv/lib/python3.10/site-packages/langchain_experimental/tabular_synthetic_data/openai.py:63\u001b[0m, in \u001b[0;36mcreate_openai_data_generator\u001b[0;34m(output_schema, llm, prompt, output_parser, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m chain \u001b[39m=\u001b[39m create_structured_output_chain(\n\u001b[1;32m     59\u001b[0m     output_schema, llm, prompt, output_parser\u001b[39m=\u001b[39moutput_parser, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[39m# Create the SyntheticDataGenerator instance with the created chain\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m generator \u001b[39m=\u001b[39m SyntheticDataGenerator(template\u001b[39m=\u001b[39;49mprompt, llm_chain\u001b[39m=\u001b[39;49mchain)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m generator\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Yash/OMSCS/Credit-Card-Recommendation/venv/lib/python3.10/site-packages/pydantic/_internal/_mock_val_ser.py:100\u001b[0m, in \u001b[0;36mMockValSer.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m# raise an AttributeError if `item` doesn't exist\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_val_or_ser, item)\n\u001b[0;32m--> 100\u001b[0m \u001b[39mraise\u001b[39;00m PydanticUserError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_message, code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_code)\n",
      "\u001b[0;31mPydanticUserError\u001b[0m: `SyntheticDataGenerator` is not fully defined; you should define `BaseCache`, then call `SyntheticDataGenerator.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined"
     ]
    }
   ],
   "source": [
    "synthetic_data_generator = create_openai_data_generator(\n",
    "    output_schema=SpendingSchema,\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=1,\n",
    "        api_key=api_key\n",
    "    ), \n",
    "    prompt=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_results = synthetic_data_generator.generate(\n",
    "    subject=\"spending_data\",\n",
    "    extra=\"Generate samples with dollar values for the transactions given that represent what people would spend and save. Make sure the year and month is before November 2024 to make it realistic. You can also add outliers in certain categories to represent people who go extreme in some areas.\" +\n",
    "    \"You can make housing between 600 and 10000, bills and utilities between 50 and 1000, dining between 50 and 1000, transport between 20 and 500, fitness between 0 and 400, travel between 0 and 4000, entertainment between 10 and 3000, and savings between 0 and 3000. Make it as realistic as possible\",\n",
    "    runs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synthetic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SpendingSchema(user_id='U003', month='August 2023', housing=5000, bills_utilities=800, dining=600, transport=400, fitness=200, travel=2000, entertainment=2500, savings=2500),\n",
       " SpendingSchema(user_id='U004', month='March 2024', housing=2500, bills_utilities=300, dining=800, transport=350, fitness=50, travel=1500, entertainment=1200, savings=1500),\n",
       " SpendingSchema(user_id='U005', month='June 2024', housing=7200, bills_utilities=600, dining=900, transport=300, fitness=250, travel=3500, entertainment=2800, savings=2700),\n",
       " SpendingSchema(user_id='U006', month='August 2023', housing=4000, bills_utilities=200, dining=500, transport=150, fitness=75, travel=3000, entertainment=2000, savings=2000),\n",
       " SpendingSchema(user_id='U007', month='July 2022', housing=7800, bills_utilities=450, dining=800, transport=200, fitness=150, travel=3700, entertainment=2500, savings=2800),\n",
       " SpendingSchema(user_id='U008', month='September 2023', housing=7500, bills_utilities=300, dining=700, transport=180, fitness=100, travel=2500, entertainment=1500, savings=2500),\n",
       " SpendingSchema(user_id='U009', month='August 2024', housing=6700, bills_utilities=400, dining=600, transport=150, fitness=200, travel=2800, entertainment=1800, savings=2700),\n",
       " SpendingSchema(user_id='U010', month='July 2024', housing=8200, bills_utilities=450, dining=800, transport=200, fitness=350, travel=3200, entertainment=2500, savings=2800),\n",
       " SpendingSchema(user_id='U011', month='June 2024', housing=7200, bills_utilities=300, dining=700, transport=180, fitness=250, travel=3200, entertainment=2000, savings=2900),\n",
       " SpendingSchema(user_id='U012', month='May 2024', housing=6800, bills_utilities=250, dining=600, transport=150, fitness=300, travel=3500, entertainment=2200, savings=2500)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/d79ycrgx64v30y71jr_0ljlm0000gn/T/ipykernel_76062/488733686.py:50: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "ename": "PydanticUserError",
     "evalue": "`SyntheticDataGenerator` is not fully defined; you should define `BaseCache`, then call `SyntheticDataGenerator.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 57\u001b[0m\n\u001b[1;32m     50\u001b[0m llm \u001b[39m=\u001b[39m ChatOpenAI(\n\u001b[1;32m     51\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m,\n\u001b[1;32m     52\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m# Ensure a supported model is used\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myour_openai_api_key\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Replace with your OpenAI API key\u001b[39;00m\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39m# Create synthetic data generator\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m synthetic_data_generator \u001b[39m=\u001b[39m create_openai_data_generator(\n\u001b[1;32m     58\u001b[0m     output_schema\u001b[39m=\u001b[39;49mSpendingSchema,\n\u001b[1;32m     59\u001b[0m     llm\u001b[39m=\u001b[39;49mllm,\n\u001b[1;32m     60\u001b[0m     prompt\u001b[39m=\u001b[39;49mfew_shot_prompt,\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[39m# Generate synthetic data\u001b[39;00m\n\u001b[1;32m     64\u001b[0m synthetic_results \u001b[39m=\u001b[39m synthetic_data_generator\u001b[39m.\u001b[39mgenerate(\n\u001b[1;32m     65\u001b[0m     subject\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUser ID: U003, March 2023 spending\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m     extra\u001b[39m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     runs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m     72\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Yash/OMSCS/Credit-Card-Recommendation/venv/lib/python3.10/site-packages/langchain_experimental/tabular_synthetic_data/openai.py:63\u001b[0m, in \u001b[0;36mcreate_openai_data_generator\u001b[0;34m(output_schema, llm, prompt, output_parser, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m chain \u001b[39m=\u001b[39m create_structured_output_chain(\n\u001b[1;32m     59\u001b[0m     output_schema, llm, prompt, output_parser\u001b[39m=\u001b[39moutput_parser, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[39m# Create the SyntheticDataGenerator instance with the created chain\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m generator \u001b[39m=\u001b[39m SyntheticDataGenerator(template\u001b[39m=\u001b[39;49mprompt, llm_chain\u001b[39m=\u001b[39;49mchain)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m generator\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Yash/OMSCS/Credit-Card-Recommendation/venv/lib/python3.10/site-packages/pydantic/_internal/_mock_val_ser.py:100\u001b[0m, in \u001b[0;36mMockValSer.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m# raise an AttributeError if `item` doesn't exist\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_val_or_ser, item)\n\u001b[0;32m--> 100\u001b[0m \u001b[39mraise\u001b[39;00m PydanticUserError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_message, code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_code)\n",
      "\u001b[0;31mPydanticUserError\u001b[0m: `SyntheticDataGenerator` is not fully defined; you should define `BaseCache`, then call `SyntheticDataGenerator.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_experimental.tabular_synthetic_data.openai import (\n",
    "    create_openai_data_generator,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Define Spending Schema using Pydantic\n",
    "class SpendingSchema(BaseModel):\n",
    "    user_id: str = Field(..., description=\"Unique identifier for the user\")\n",
    "    month: str = Field(..., description=\"Month of the spending\")\n",
    "    housing: int = Field(..., description=\"Spending on housing\")\n",
    "    bills_utilities: int = Field(..., description=\"Spending on bills and utilities\")\n",
    "    dining: int = Field(..., description=\"Spending on dining\")\n",
    "    transport: int = Field(..., description=\"Spending on transportation\")\n",
    "    fitness: int = Field(..., description=\"Spending on fitness activities\")\n",
    "    travel: int = Field(..., description=\"Spending on travel\")\n",
    "    entertainment: int = Field(..., description=\"Spending on entertainment\")\n",
    "    savings: int = Field(..., description=\"Savings for the month\")\n",
    "\n",
    "# Examples for FewShotPromptTemplate\n",
    "examples = [\n",
    "    {\n",
    "        \"subject\": \"User ID: U001, Month: January 2023 spending\",\n",
    "        \"extra\": \"Housing: 800, Bills & Utilities: 210, Dining: 400, Transport: 100, Fitness: 60, Travel: 400, Entertainment: 300, Savings: 1500\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"User ID: U002, Month: February 2023 spending\",\n",
    "        \"extra\": \"Housing: 1300, Bills & Utilities: 150, Dining: 200, Transport: 250, Fitness: 20, Travel: 100, Entertainment: 700, Savings: 600\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the example template\n",
    "example_template = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"extra\"],\n",
    "    template=\"{subject}:\\n{extra}\"\n",
    ")\n",
    "\n",
    "# Define the few-shot prompt template\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    prefix=\"Below are examples of spending data:\",\n",
    "    examples=examples,\n",
    "    suffix=\"Generate realistic synthetic spending data with variations.\",\n",
    "    input_variables=[\"subject\", \"extra\"],\n",
    "    example_prompt=example_template\n",
    ")\n",
    "\n",
    "# Initialize ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    model=\"gpt-4\",  # Ensure a supported model is used\n",
    "    api_key=\"your_openai_api_key\"  # Replace with your OpenAI API key\n",
    ")\n",
    "\n",
    "# Create synthetic data generator\n",
    "synthetic_data_generator = create_openai_data_generator(\n",
    "    output_schema=SpendingSchema,\n",
    "    llm=llm,\n",
    "    prompt=few_shot_prompt,\n",
    ")\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_results = synthetic_data_generator.generate(\n",
    "    subject=\"User ID: U003, March 2023 spending\",\n",
    "    extra=(\n",
    "        \"Housing: 1000-5000, Bills & Utilities: 100-1000, Dining: 50-800, \"\n",
    "        \"Transport: 50-400, Fitness: 0-300, Travel: 0-2000, Entertainment: \"\n",
    "        \"50-1000, Savings: 100-3000. Include some outliers for variety.\"\n",
    "    ),\n",
    "    runs=10\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for idx, result in enumerate(synthetic_results, start=1):\n",
    "    print(f\"Sample {idx}: {result.dict()}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id     month  year  housing  bills_utilities  dining  \\\n",
      "0  hansonbrittany   January  2023     2922              671     224   \n",
      "1  hansonbrittany  February  2023      844              848      96   \n",
      "2  hansonbrittany     March  2023     2489             1251     189   \n",
      "3  hansonbrittany     April  2023     1858              583     792   \n",
      "4  hansonbrittany       May  2023     3132              822     131   \n",
      "\n",
      "   transport  fitness  travel  entertainment  savings  \n",
      "0        256      236    1437            913     1487  \n",
      "1         60      111     570            922      232  \n",
      "2        281      267    1898            543     3869  \n",
      "3        280      112     349            581     5319  \n",
      "4        275       97     385            776      894  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker for generating user profiles\n",
    "faker = Faker()\n",
    "\n",
    "# Define spending categories and realistic ranges for spending\n",
    "categories = {\n",
    "    \"housing\": (800, 5000),\n",
    "    \"bills_utilities\": (50, 1000),\n",
    "    \"dining\": (50, 800),\n",
    "    \"transport\": (20, 400),\n",
    "    \"fitness\": (0, 300),\n",
    "    \"travel\": (0, 2000),\n",
    "    \"entertainment\": (10, 1000),\n",
    "    \"savings\": (100, 5000),\n",
    "}\n",
    "\n",
    "def generate_user_data(user_id, month, year):\n",
    "    \"\"\"Generates realistic spending data for a single user.\"\"\"\n",
    "    data = {\n",
    "        \"user_id\": user_id,\n",
    "        \"month\": month,\n",
    "        \"year\": year,\n",
    "    }\n",
    "    for category, (min_val, max_val) in categories.items():\n",
    "        # Add realistic variation and outliers\n",
    "        if random.random() < 0.05:  # 5% chance of an extreme value (outlier)\n",
    "            data[category] = random.randint(max_val, max_val * 2)\n",
    "        else:\n",
    "            data[category] = random.randint(min_val, max_val)\n",
    "    return data\n",
    "\n",
    "def generate_synthetic_dataset(num_users=100, months=12):\n",
    "    \"\"\"Generates a synthetic dataset for multiple users over a period.\"\"\"\n",
    "    dataset = []\n",
    "    for _ in range(num_users):\n",
    "        user_id = faker.unique.user_name()\n",
    "        for month in range(1, months + 1):\n",
    "            year = 2023\n",
    "            month_name = pd.Timestamp(year=year, month=month, day=1).strftime(\"%B\")\n",
    "            dataset.append(generate_user_data(user_id, month_name, year))\n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "# Generate a dataset for 100 users over 12 months\n",
    "synthetic_dataset = generate_synthetic_dataset(num_users=10000, months=12)\n",
    "\n",
    "# Save to CSV or view as a sample\n",
    "synthetic_dataset.to_csv(\"synthetic_spending_data.csv\", index=False)\n",
    "print(synthetic_dataset.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
